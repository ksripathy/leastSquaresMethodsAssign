{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "$E(\\underline{y}) = Ax$\n",
    "\n",
    "$D(\\underline{y}) = Q_y = \\sigma^2I_3$\n",
    "\n",
    "$x = \\begin{bmatrix} x_1 & x_2 \\end{bmatrix}^T$\n",
    "\n",
    "$A = \\begin{bmatrix} 1 & 0 \\\\ -1 & 1 \\\\ 0 & -1 \\\\ \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,0],[-1,1],[0,-1]])\n",
    "inv_AT_A = inv(A.T @ A)\n",
    "sqrt_inv_AT_A = np.sqrt(inv_AT_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(A^TA)^-1 = \\begin{bmatrix} 0.67 & 0.33 \\\\ 0.33 & 0.67 \\\\ \\end{bmatrix}$\n",
    "\n",
    "$Q_{\\hat{x}} = \\sigma^2(A^TA)^{-1}$\n",
    "\n",
    "$Q_{\\hat{x}} = \\begin{bmatrix} 0.67 \\sigma^2 & 0.33 \\sigma^2 \\\\ 0.33 \\sigma^2 & 0.67 \\sigma^2 \\end{bmatrix}$\n",
    "\n",
    "$\\sigma_{x_1} = 0.82\\sigma$\n",
    "\n",
    "# Question 2\n",
    "\n",
    "$\\underline{y} = \\begin{bmatrix} \\underline{y}_1 & \\underline{y}_2 & \\underline{y}_3 & \\underline{y}_4 \\end{bmatrix}^T$\n",
    "\n",
    "\n",
    "$E(\\underline{y}) = \\begin{bmatrix} x & x & x & x \\end{bmatrix}^T$\n",
    "\n",
    "$Q_y = \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 2 & 0 & 0 \\\\ 0 & 0 & 3 & 0 \\\\ 0 & 0 & 0 & 4\\\\ \\end{bmatrix}$\n",
    "\n",
    "## 2-a\n",
    "\n",
    "$E(\\underline{y}) = Ax$\n",
    "\n",
    "$A = \\begin{bmatrix} 1 & 1 & 1 & 1  \\end{bmatrix}^T$\n",
    "\n",
    "## 2-b\n",
    "\n",
    "$\\hat{\\underline{x}} = (A^TQ_y^{-1}A)^{-1}A^TQ_y^{-1}\\underline{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1],[1],[1],[1]])\n",
    "Qy = np.array([[1,0,0,0],[0,2,0,0],[0,0,3,0],[0,0,0,4]])\n",
    "\n",
    "W = inv(Qy)\n",
    "inv_AT_W_A = inv(A.T @ W @ A)\n",
    "AT_W = A.T @ W\n",
    "xhat_matrix = inv_AT_W_A @ AT_W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{\\underline{x}} = \\begin{bmatrix} 0.48 & 0.24 & 0.16 & 0.12 \\end{bmatrix}\\begin{bmatrix} \\underline{y}_1 & \\underline{y}_2 & \\underline{y}_3 & \\underline{y}_4 \\end{bmatrix}^T$\n",
    "\n",
    "$\\hat{\\underline{x}} = 0.48\\underline{y}_1 + 0.24\\underline{y}_2 + 0.16\\underline{y}_3 + 0.12\\underline{y}_4$\n",
    "\n",
    "## 2-c\n",
    "\n",
    "$Q_{\\hat{x}} = (A^TQ_y^{-1}A)^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qxhat = inv_AT_W_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Q_{\\hat{x}} = 0.48$\n",
    "\n",
    "# Question 3\n",
    "\n",
    "$\\underline{y} = \\begin{bmatrix} 319 & 325 & 321 \\end{bmatrix}^T$\n",
    "\n",
    "$Q_y = \\begin{bmatrix} 9 & 0 & 0 \\\\ 0 & 9 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$\n",
    "\n",
    "$A = \\begin{bmatrix} 1 & 1 & 1 \\end{bmatrix}^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[319],[325],[321]])\n",
    "A = np.array([[1],[1],[1]])\n",
    "Qy = np.array([[9,0,0],[0,9,0],[0,0,1]])\n",
    "\n",
    "W = inv(Qy)\n",
    "Qxhat = inv(A.T @ W @ A)\n",
    "xhat = Qxhat @ A.T @ W @ y\n",
    "std_xhat = np.sqrt(Qxhat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{\\underline{x}} = (A^TQ_y^{-1}A)^{-1}A^TQ_y^{-1}\\underline{y}$\n",
    "\n",
    "$\\hat{\\underline{x}} = 321.18$ cm\n",
    "\n",
    "$\\sigma_x = 0.905$ cm\n",
    "\n",
    "# Question 4\n",
    "\n",
    "$\\underline{y} = \\begin{bmatrix} \\underline{y}_1 & \\underline{y}_2 & \\underline{y}_3  \\end{bmatrix}^T$\n",
    "\n",
    "$x = \\begin{bmatrix} x_1 & x_2 \\end{bmatrix}^T$\n",
    "\n",
    "$A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\\\ \\end{bmatrix}$\n",
    "\n",
    "$E(\\underline{y}) = \\begin{bmatrix} \\bar{y}_1 \\\\ \\bar{y}_2 \\\\ \\bar{y}_3 \\\\ \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\\\ \\end{bmatrix}\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\end{bmatrix}$\n",
    "\n",
    "$Q_y = \\sigma^2 I_3$\n",
    "\n",
    "## 4-a\n",
    "\n",
    "$\\hat{\\underline{x}} = (A^TQ_y^{-1}A)^{-1}A^TQ_y^{-1}\\underline{y}$\n",
    "\n",
    "$\\hat{\\underline{x}} = (A^TA)^{-1}A^T\\underline{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,0],[0,1],[1,1]])\n",
    "xhat_matrix = inv(A.T @ A) @ A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{\\underline{x}} = \\begin{bmatrix} 0.67 & -0.33 & 0.33 \\\\ -0.33 & 0.67 & 0.33 \\\\ \\end{bmatrix}\\begin{bmatrix} \\underline{y}_1 \\\\ \\underline{y}_2 \\\\ \\underline{y}_3 \\\\ \\end{bmatrix}$\n",
    "\n",
    "$\\hat{\\underline{x}}_1 = 0.67\\underline{y}_1 -0.33\\underline{y}_2 + 0.33\\underline{y}_3$\n",
    "\n",
    "$\\hat{\\underline{x}}_2 = -0.33\\underline{y}_1 +0.67\\underline{y}_2 + 0.33\\underline{y}_3$\n",
    "\n",
    "## 4-b\n",
    "\n",
    "$Q_{\\hat{x}} = \\sigma^2(A^TA)^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_AT_A = inv(A.T @ A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Q_{\\hat{x}} = \\sigma^2 \\begin{bmatrix} 0.67 & -0.33 \\\\ -0.33 & 0.67 \\\\ \\end{bmatrix}$\n",
    "\n",
    "Let $\\hat{\\underline{x}}_3 = \\hat{\\underline{x}}_1 + \\hat{\\underline{x}}_2$\n",
    "\n",
    "$\\hat{\\underline{x}}_3 = B \\begin{bmatrix} \\hat{\\underline{x}}_1 \\\\ \\hat{\\underline{x}}_2 \\end{bmatrix}$\n",
    "\n",
    "$B = \\begin{bmatrix} 1 & 1 \\end{bmatrix}$\n",
    "\n",
    "For linear case, the variance propagation law is $Q_{\\hat{x}_3} = BQ_{\\hat{x}}B^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qxhat_matrix = inv_AT_A\n",
    "B = np.array([[1,1]])\n",
    "\n",
    "Qx3hat_matrix = B @ Qxhat_matrix @ B.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Q_{\\hat{x}_3} = 0.67 \\sigma^2$\n",
    "\n",
    "# Question 5\n",
    "\n",
    "$\\underline{y} = \\begin{bmatrix} \\underline{y}_1 & \\underline{y}_2 \\end{bmatrix}^T$\n",
    "\n",
    "\n",
    "$E(\\underline{y}) = \\begin{bmatrix} x & x \\end{bmatrix}^T$\n",
    "\n",
    "$A = \\begin{bmatrix} 1 & 1 \\end{bmatrix}^T$\n",
    "\n",
    "$Q_y = \\sigma^2\\begin{bmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{bmatrix}; \\rho =0,\\pm1$\n",
    "\n",
    "## 5-a\n",
    "\n",
    "$Q_{\\hat{x}} = (A^TQ_y^{-1}A)^{-1}$\n",
    "\n",
    "$Q_y^{-1} = \\sigma^{-2}(1-\\rho^2)^{-1}\\begin{bmatrix}1 & -\\rho \\\\ -\\rho & 1 \\end{bmatrix}$\n",
    "\n",
    "$Q_{\\hat{x}} = \\left(\\begin{bmatrix} 1 & 1 \\end{bmatrix}\\sigma^{-2}(1-\\rho^2)^{-1}\\begin{bmatrix}1 & -\\rho \\\\ -\\rho & 1 \\end{bmatrix}\\begin{bmatrix} 1 \\\\ 1 \\\\ \\end{bmatrix}\\right)^{-1}$\n",
    "\n",
    "$Q_{\\hat{x}} = \\sigma^2(1-\\rho^2)\\left(\\begin{bmatrix} 1 & 1 \\end{bmatrix}\\begin{bmatrix} 1 - \\rho \\\\ 1 - \\rho \\\\ \\end{bmatrix}\\right)^{-1}$\n",
    "\n",
    "$$Q_{\\hat{x}} = \\frac{\\sigma^2(1+\\rho)}{2}$$\n",
    "\n",
    "## 5-b\n",
    "\n",
    "$$Q_{\\hat{x}}(\\rho = 0) = \\frac{\\sigma^2}{2}$$\n",
    "\n",
    "For $\\rho = 0$, the measurements are independent. $Q_{\\hat{x}}$ is equivalent to the variance of the mean of the independent measurements.\n",
    "\n",
    "$$Q_{\\hat{x}}(\\rho = 1) = \\sigma^2$$\n",
    "$$Q_{\\hat{x}}(\\rho = -1) = 0$$\n",
    "\n",
    "For $\\rho = \\pm1$, The measurments are perfectly correlated. If the correlation is perfectly positive ($\\rho = 1$) then the variance of BLUE of x achieves highest possible value. This is because, for perfect positive correlation, the uncertainities get added up in the BLUE, and the variance of the mean in this case will be equl to the variance of the individual measurement. \n",
    "\n",
    "If the correlation is perfectly negative ($\\rho = -1$), then the variance of BLUE of x acheives lowest possible value. This is because, for perfect negative correlation, the uncertainities get cancelled in the BLUE, causing the variance of the mean to become zero.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "email": "K.Sripathy@tudelft.nl",
    "name": "Kiran Sripathy"
   },
   {
    "email": "S.Chellini@tudelft.nl",
    "name": "Simone Chellini"
   }
  ],
  "date": "June 20, 2024",
  "kernelspec": {
   "display_name": "devEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "title": "Assignment 4: Gauss Markov Theorem"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
